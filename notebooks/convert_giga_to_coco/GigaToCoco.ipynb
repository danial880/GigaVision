{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "178faaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f0b3c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('giga_annotations/person_bbox_train.json')\n",
    "person_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b1de007",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_images = []\n",
    "person_ann = []\n",
    "ann_id = 1\n",
    "for key in person_data.keys():\n",
    "    image_height = int(person_data[key]['image size']['height'])\n",
    "    image_width = int(person_data[key]['image size']['width'])\n",
    "    image_id = person_data[key]['image id']\n",
    "    coco_images.append({\"file_name\" : key.split('/')[1], \n",
    "                        \"id\" : image_id,\n",
    "                        \"license\" : 1,\n",
    "                        \"url\" : \"\",\n",
    "                        \"height\" : image_height,\n",
    "                        \"width\" : image_width})\n",
    "    for item in person_data[key]['objects list']:\n",
    "        if item['category']!='person':\n",
    "            xmin=int(item['rect']['tl']['x']*image_width)\n",
    "            ymin=int(item['rect']['tl']['y']*image_height)\n",
    "            xmax=int(item['rect']['br']['x']*image_width)\n",
    "            ymax=int(item['rect']['br']['y']*image_height)\n",
    "        else:\n",
    "            xmin=int(item['rects']['full body']['tl']['x']*image_width)\n",
    "            ymin=int(item['rects']['full body']['tl']['y']*image_height)\n",
    "            xmax=int(item['rects']['full body']['br']['x']*image_width)\n",
    "            ymax=int(item['rects']['full body']['br']['y']*image_height)\n",
    "        w_bbox=xmax-xmin\n",
    "        h_bbox=ymax-ymin\n",
    "        person_ann.append({\"segmentation\" : [],\n",
    "                            \"area\" : np.float64(w_bbox*h_bbox),\n",
    "                            \"iscrowd\" : 0,\n",
    "                            \"image_id\" : image_id,\n",
    "                            \"bbox\" : [xmin, ymin, w_bbox, h_bbox],\n",
    "                            \"category_id\" : 2,\n",
    "                            \"id\": ann_id})\n",
    "        ann_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e809a573",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('giga_annotations/vehicle_bbox_train.json')\n",
    "vehicle_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7295e7dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_ann = []\n",
    "for key in vehicle_data.keys():\n",
    "    image_height = int(vehicle_data[key]['image size']['height'])\n",
    "    image_width = int(vehicle_data[key]['image size']['width'])\n",
    "    image_id = vehicle_data[key]['image id']\n",
    "    for item in vehicle_data[key]['objects list']:\n",
    "        xmin=int(item['rect']['tl']['x']*image_width)\n",
    "        ymin=int(item['rect']['tl']['y']*image_height)\n",
    "        xmax=int(item['rect']['br']['x']*image_width)\n",
    "        ymax=int(item['rect']['br']['y']*image_height)\n",
    "        w_bbox=xmax-xmin\n",
    "        h_bbox=ymax-ymin\n",
    "        vehicle_ann.append({\"segmentation\" : [],\n",
    "                            \"area\" : np.float64(w_bbox*h_bbox),\n",
    "                            \"iscrowd\" : 0,\n",
    "                            \"image_id\" : image_id,\n",
    "                            \"bbox\" : [xmin, ymin, w_bbox, h_bbox],\n",
    "                            \"category_id\" : 1,\n",
    "                            \"id\": ann_id})\n",
    "        ann_id += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f4a3fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "122865\n"
     ]
    }
   ],
   "source": [
    "annotations = []\n",
    "annotations.extend(person_ann)\n",
    "annotations.extend(vehicle_ann)\n",
    "print(len(annotations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0d78edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco={}\n",
    "coco[\"info\"] = {\"year\" : \"2023\",\n",
    "                \"version\" : \"1.0\",\n",
    "                \"description\" : \"Giga Vision COCO\",\n",
    "                \"contributor\" : \"DilisionAI\",\n",
    "                \"url\" : \"\",\n",
    "                \"date_created\" : \"19 Jan\"\n",
    "                }\n",
    "coco[\"licenses\"] = [{\"id\": 1,\n",
    "                  \"name\": \"Attribution-NonCommercial\",\n",
    "                  \"url\": \"http://creativecommons.org/licenses/by-nc-sa/2.0/\"\n",
    "                 }]\n",
    "\n",
    "coco[\"categories\"] = [{'supercategory': 'person', 'id': 2, 'name': 'person'},\n",
    "                     {'supercategory': 'vehicle', 'id': 1, 'name': 'vehicle'}]\n",
    "coco['images'] = coco_images\n",
    "coco['annotations'] = annotations\n",
    "with open('giga_train_coco.json', 'w') as json_file:\n",
    "    json.dump(coco, json_file, sort_keys=True, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
